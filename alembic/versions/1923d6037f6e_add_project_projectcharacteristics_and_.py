"""Add Project, ProjectCharacteristics, and StandardEpicTemplate tables

Revision ID: 1923d6037f6e
Revises: 8e244eaab655
Create Date: 2025-11-09 23:15:03.922891

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "1923d6037f6e"
down_revision: Union[str, Sequence[str], None] = "8e244eaab655"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "standard_epic_templates",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("name", sa.String(length=200), nullable=False),
        sa.Column("description", sa.Text(), nullable=True),
        sa.Column("typical_hours_min", sa.Integer(), nullable=True),
        sa.Column("typical_hours_max", sa.Integer(), nullable=True),
        sa.Column("order", sa.Integer(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_standard_epic_templates_name"),
        "standard_epic_templates",
        ["name"],
        unique=True,
    )
    op.create_table(
        "project_characteristics",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("project_key", sa.String(length=50), nullable=False),
        sa.Column("be_integrations", sa.Integer(), nullable=False),
        sa.Column("custom_theme", sa.Integer(), nullable=False),
        sa.Column("custom_designs", sa.Integer(), nullable=False),
        sa.Column("ux_research", sa.Integer(), nullable=False),
        sa.Column("extensive_customizations", sa.Integer(), nullable=False),
        sa.Column("project_oversight", sa.Integer(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["project_key"],
            ["projects.key"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_project_characteristics_project_key"),
        "project_characteristics",
        ["project_key"],
        unique=True,
    )
    op.drop_table("meeting_project_connections")
    op.drop_table("celery_tasksetmeta")
    op.drop_table("user_preferences")
    op.drop_index(op.f("idx_vector_sync_source"), table_name="vector_sync_status")
    op.drop_table("vector_sync_status")
    op.drop_index(
        op.f("ix_query_expansions_original_term"), table_name="query_expansions"
    )
    op.drop_table("query_expansions")
    op.drop_table("slack_sessions")
    op.drop_index(
        op.f("idx_project_monthly_forecast_month_year"),
        table_name="project_monthly_forecast",
    )
    op.drop_index(
        op.f("idx_project_monthly_forecast_project_key"),
        table_name="project_monthly_forecast",
    )
    op.drop_table("project_monthly_forecast")
    op.drop_table("project_changes")
    op.drop_index(op.f("idx_project_keywords_user_id"), table_name="project_keywords")
    op.drop_table("project_keywords")
    op.drop_table("search_feedback")
    op.drop_table("celery_taskmeta")
    op.drop_index(
        op.f("idx_project_resource_mappings_key"),
        table_name="project_resource_mappings",
    )
    op.drop_table("project_resource_mappings")
    op.drop_constraint(
        op.f("epic_baselines_epic_category_key"), "epic_baselines", type_="unique"
    )
    op.drop_index(op.f("ix_epic_baselines_project_count"), table_name="epic_baselines")
    op.drop_index(op.f("ix_epic_baselines_variance_level"), table_name="epic_baselines")
    op.drop_index(op.f("ix_epic_baselines_epic_category"), table_name="epic_baselines")
    op.create_index(
        op.f("ix_epic_baselines_epic_category"),
        "epic_baselines",
        ["epic_category"],
        unique=True,
    )
    op.alter_column(
        "epic_budgets",
        "created_at",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "epic_budgets",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.drop_index(op.f("idx_feedback_items_recipient"), table_name="feedback_items")
    op.drop_index(op.f("idx_feedback_items_status"), table_name="feedback_items")
    op.drop_index(op.f("idx_feedback_items_user_id"), table_name="feedback_items")
    op.drop_index(op.f("idx_learnings_user_id"), table_name="learnings")
    op.alter_column(
        "processed_meetings",
        "ai_provider",
        existing_type=sa.VARCHAR(length=50),
        comment=None,
        existing_comment="AI provider used for analysis: openai, anthropic, or google",
        existing_nullable=True,
    )
    op.alter_column(
        "processed_meetings",
        "ai_model",
        existing_type=sa.VARCHAR(length=100),
        comment=None,
        existing_comment="Specific AI model used for analysis",
        existing_nullable=True,
    )
    op.drop_index(op.f("idx_digest_cache_composite"), table_name="project_digest_cache")
    op.alter_column(
        "projects",
        "is_active",
        existing_type=sa.BOOLEAN(),
        nullable=False,
        existing_server_default=sa.text("true"),
    )
    op.alter_column(
        "projects",
        "created_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=False,
        existing_server_default=sa.text("CURRENT_TIMESTAMP"),
    )
    op.alter_column(
        "projects",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=False,
        existing_server_default=sa.text("CURRENT_TIMESTAMP"),
    )
    op.drop_index(op.f("idx_projects_is_active"), table_name="projects")
    op.drop_index(op.f("idx_projects_project_work_type"), table_name="projects")
    op.drop_column("projects", "description")
    op.drop_column("projects", "send_meeting_emails")
    op.drop_column("projects", "weekly_meeting_day")
    op.drop_column("projects", "project_work_type")
    op.drop_column("projects", "launch_date")
    op.drop_column("projects", "lead")
    op.drop_column("projects", "show_budget_tab")
    op.drop_column("projects", "total_hours")
    op.drop_column("projects", "cumulative_hours")
    op.drop_column("projects", "retainer_hours")
    op.drop_column("projects", "start_date")
    op.drop_index(op.f("idx_todo_items_source"), table_name="todo_items")
    op.drop_index(op.f("idx_todo_items_status"), table_name="todo_items")
    op.drop_index(op.f("idx_todo_items_user_id"), table_name="todo_items")
    op.drop_column("todo_items", "source")
    op.alter_column(
        "user_teams",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        nullable=True,
        existing_server_default=sa.text("CURRENT_TIMESTAMP"),
    )
    op.alter_column(
        "user_watched_projects", "user_id", existing_type=sa.INTEGER(), nullable=False
    )
    op.drop_index(
        op.f("idx_user_watched_projects_user_id"), table_name="user_watched_projects"
    )
    op.drop_constraint(
        op.f("user_watched_projects_user_id_project_key_key"),
        "user_watched_projects",
        type_="unique",
    )
    op.create_unique_constraint(
        "_user_project_watch_uc", "user_watched_projects", ["user_id", "project_key"]
    )
    op.drop_constraint(
        op.f("user_watched_projects_user_id_fkey"),
        "user_watched_projects",
        type_="foreignkey",
    )
    op.create_foreign_key(None, "user_watched_projects", "users", ["user_id"], ["id"])
    op.drop_column("user_watched_projects", "updated_at")
    op.alter_column(
        "users", "name", existing_type=sa.VARCHAR(length=255), nullable=False
    )
    op.alter_column(
        "users", "google_id", existing_type=sa.VARCHAR(length=255), nullable=False
    )
    op.alter_column(
        "users",
        "role",
        existing_type=postgresql.ENUM("NO_ACCESS", "MEMBER", "ADMIN", name="userrole"),
        nullable=False,
        existing_server_default=sa.text("'MEMBER'::userrole"),
    )
    op.drop_index(op.f("idx_users_slack_user_id"), table_name="users")
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_index(
        op.f("idx_users_slack_user_id"), "users", ["slack_user_id"], unique=False
    )
    op.alter_column(
        "users",
        "role",
        existing_type=postgresql.ENUM("NO_ACCESS", "MEMBER", "ADMIN", name="userrole"),
        nullable=True,
        existing_server_default=sa.text("'MEMBER'::userrole"),
    )
    op.alter_column(
        "users", "google_id", existing_type=sa.VARCHAR(length=255), nullable=True
    )
    op.alter_column(
        "users", "name", existing_type=sa.VARCHAR(length=255), nullable=True
    )
    op.add_column(
        "user_watched_projects",
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.drop_constraint(None, "user_watched_projects", type_="foreignkey")
    op.create_foreign_key(
        op.f("user_watched_projects_user_id_fkey"),
        "user_watched_projects",
        "users",
        ["user_id"],
        ["id"],
        ondelete="CASCADE",
    )
    op.drop_constraint(
        "_user_project_watch_uc", "user_watched_projects", type_="unique"
    )
    op.create_unique_constraint(
        op.f("user_watched_projects_user_id_project_key_key"),
        "user_watched_projects",
        ["user_id", "project_key"],
        postgresql_nulls_not_distinct=False,
    )
    op.create_index(
        op.f("idx_user_watched_projects_user_id"),
        "user_watched_projects",
        ["user_id"],
        unique=False,
    )
    op.alter_column(
        "user_watched_projects", "user_id", existing_type=sa.INTEGER(), nullable=True
    )
    op.alter_column(
        "user_teams",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        nullable=False,
        existing_server_default=sa.text("CURRENT_TIMESTAMP"),
    )
    op.add_column(
        "todo_items",
        sa.Column("source", sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    )
    op.create_index(
        op.f("idx_todo_items_user_id"), "todo_items", ["user_id"], unique=False
    )
    op.create_index(
        op.f("idx_todo_items_status"), "todo_items", ["status"], unique=False
    )
    op.create_index(
        op.f("idx_todo_items_source"), "todo_items", ["source"], unique=False
    )
    op.add_column(
        "projects",
        sa.Column("start_date", sa.DATE(), autoincrement=False, nullable=True),
    )
    op.add_column(
        "projects",
        sa.Column(
            "retainer_hours",
            sa.NUMERIC(precision=10, scale=2),
            server_default=sa.text("0"),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "projects",
        sa.Column(
            "cumulative_hours",
            sa.NUMERIC(precision=10, scale=2),
            server_default=sa.text("0"),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "projects",
        sa.Column(
            "total_hours",
            sa.NUMERIC(precision=10, scale=2),
            server_default=sa.text("0"),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "projects",
        sa.Column(
            "show_budget_tab",
            sa.BOOLEAN(),
            server_default=sa.text("true"),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "projects",
        sa.Column("lead", sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    )
    op.add_column(
        "projects",
        sa.Column("launch_date", sa.DATE(), autoincrement=False, nullable=True),
    )
    op.add_column(
        "projects",
        sa.Column(
            "project_work_type",
            sa.VARCHAR(length=50),
            server_default=sa.text("'project-based'::character varying"),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "projects",
        sa.Column("weekly_meeting_day", sa.TEXT(), autoincrement=False, nullable=True),
    )
    op.add_column(
        "projects",
        sa.Column(
            "send_meeting_emails",
            sa.BOOLEAN(),
            server_default=sa.text("false"),
            autoincrement=False,
            nullable=False,
        ),
    )
    op.add_column(
        "projects",
        sa.Column("description", sa.TEXT(), autoincrement=False, nullable=True),
    )
    op.create_index(
        op.f("idx_projects_project_work_type"),
        "projects",
        ["project_work_type"],
        unique=False,
    )
    op.create_index(
        op.f("idx_projects_is_active"), "projects", ["is_active"], unique=False
    )
    op.alter_column(
        "projects",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=True,
        existing_server_default=sa.text("CURRENT_TIMESTAMP"),
    )
    op.alter_column(
        "projects",
        "created_at",
        existing_type=postgresql.TIMESTAMP(),
        nullable=True,
        existing_server_default=sa.text("CURRENT_TIMESTAMP"),
    )
    op.alter_column(
        "projects",
        "is_active",
        existing_type=sa.BOOLEAN(),
        nullable=True,
        existing_server_default=sa.text("true"),
    )
    op.create_index(
        op.f("idx_digest_cache_composite"),
        "project_digest_cache",
        ["project_key", "days", "include_context", "created_at"],
        unique=False,
    )
    op.alter_column(
        "processed_meetings",
        "ai_model",
        existing_type=sa.VARCHAR(length=100),
        comment="Specific AI model used for analysis",
        existing_nullable=True,
    )
    op.alter_column(
        "processed_meetings",
        "ai_provider",
        existing_type=sa.VARCHAR(length=50),
        comment="AI provider used for analysis: openai, anthropic, or google",
        existing_nullable=True,
    )
    op.create_index(
        op.f("idx_learnings_user_id"), "learnings", ["user_id"], unique=False
    )
    op.create_index(
        op.f("idx_feedback_items_user_id"), "feedback_items", ["user_id"], unique=False
    )
    op.create_index(
        op.f("idx_feedback_items_status"), "feedback_items", ["status"], unique=False
    )
    op.create_index(
        op.f("idx_feedback_items_recipient"),
        "feedback_items",
        ["recipient"],
        unique=False,
    )
    op.alter_column(
        "epic_budgets",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        nullable=True,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "epic_budgets",
        "created_at",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        nullable=True,
        existing_server_default=sa.text("now()"),
    )
    op.drop_index(op.f("ix_epic_baselines_epic_category"), table_name="epic_baselines")
    op.create_index(
        op.f("ix_epic_baselines_epic_category"),
        "epic_baselines",
        ["epic_category"],
        unique=False,
    )
    op.create_index(
        op.f("ix_epic_baselines_variance_level"),
        "epic_baselines",
        ["variance_level"],
        unique=False,
    )
    op.create_index(
        op.f("ix_epic_baselines_project_count"),
        "epic_baselines",
        ["project_count"],
        unique=False,
    )
    op.create_unique_constraint(
        op.f("epic_baselines_epic_category_key"),
        "epic_baselines",
        ["epic_category"],
        postgresql_nulls_not_distinct=False,
    )
    op.create_table(
        "project_resource_mappings",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column("project_key", sa.TEXT(), autoincrement=False, nullable=False),
        sa.Column("project_name", sa.TEXT(), autoincrement=False, nullable=False),
        sa.Column("slack_channel_ids", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column("notion_page_ids", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column("github_repos", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column("jira_project_keys", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            autoincrement=False,
            nullable=True,
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("project_resource_mappings_pkey")),
        sa.UniqueConstraint(
            "project_key",
            name=op.f("project_resource_mappings_project_key_key"),
            postgresql_include=[],
            postgresql_nulls_not_distinct=False,
        ),
    )
    op.create_index(
        op.f("idx_project_resource_mappings_key"),
        "project_resource_mappings",
        ["project_key"],
        unique=False,
    )
    op.create_table(
        "celery_taskmeta",
        sa.Column("id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column(
            "task_id", sa.VARCHAR(length=155), autoincrement=False, nullable=True
        ),
        sa.Column("status", sa.VARCHAR(length=50), autoincrement=False, nullable=True),
        sa.Column("result", postgresql.BYTEA(), autoincrement=False, nullable=True),
        sa.Column(
            "date_done", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.Column("traceback", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column("name", sa.VARCHAR(length=155), autoincrement=False, nullable=True),
        sa.Column("args", postgresql.BYTEA(), autoincrement=False, nullable=True),
        sa.Column("kwargs", postgresql.BYTEA(), autoincrement=False, nullable=True),
        sa.Column("worker", sa.VARCHAR(length=155), autoincrement=False, nullable=True),
        sa.Column("retries", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column("queue", sa.VARCHAR(length=155), autoincrement=False, nullable=True),
        sa.PrimaryKeyConstraint("id", name=op.f("celery_taskmeta_pkey")),
        sa.UniqueConstraint(
            "task_id",
            name=op.f("celery_taskmeta_task_id_key"),
            postgresql_include=[],
            postgresql_nulls_not_distinct=False,
        ),
    )
    op.create_table(
        "search_feedback",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column("user_id", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "slack_user_id", sa.VARCHAR(length=50), autoincrement=False, nullable=True
        ),
        sa.Column("query", sa.TEXT(), autoincrement=False, nullable=False),
        sa.Column("rating", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("feedback_text", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column("result_count", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "result_sources",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "top_result_source",
            sa.VARCHAR(length=50),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "detail_level", sa.VARCHAR(length=20), autoincrement=False, nullable=True
        ),
        sa.Column(
            "project_key", sa.VARCHAR(length=10), autoincrement=False, nullable=True
        ),
        sa.Column("response_time_ms", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column("summary_length", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("search_feedback_pkey")),
    )
    op.create_table(
        "project_keywords",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column("user_id", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "keyword", sa.VARCHAR(length=100), autoincrement=False, nullable=False
        ),
        sa.Column(
            "project_key", sa.VARCHAR(length=50), autoincrement=False, nullable=False
        ),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            autoincrement=False,
            nullable=True,
        ),
        sa.ForeignKeyConstraint(
            ["user_id"],
            ["users.id"],
            name=op.f("project_keywords_user_id_fkey"),
            ondelete="CASCADE",
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("project_keywords_pkey")),
    )
    op.create_index(
        op.f("idx_project_keywords_user_id"),
        "project_keywords",
        ["user_id"],
        unique=False,
    )
    op.create_table(
        "project_changes",
        sa.Column("id", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("project_key", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("change_type", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("ticket_key", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("ticket_title", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("old_value", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("new_value", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("assignee", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("reporter", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("priority", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("status", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "change_timestamp",
            postgresql.TIMESTAMP(),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "detected_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "change_details",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("project_changes_pkey")),
    )
    op.create_table(
        "project_monthly_forecast",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column(
            "project_key", sa.VARCHAR(length=50), autoincrement=False, nullable=False
        ),
        sa.Column("month_year", sa.DATE(), autoincrement=False, nullable=False),
        sa.Column(
            "forecasted_hours",
            sa.NUMERIC(precision=10, scale=2),
            server_default=sa.text("0"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "actual_monthly_hours",
            sa.NUMERIC(precision=10, scale=2),
            server_default=sa.text("0"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            autoincrement=False,
            nullable=True,
        ),
        sa.ForeignKeyConstraint(
            ["project_key"],
            ["projects.key"],
            name=op.f("project_monthly_forecast_project_key_fkey"),
            ondelete="CASCADE",
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("project_monthly_forecast_pkey")),
        sa.UniqueConstraint(
            "project_key",
            "month_year",
            name=op.f("unique_project_month"),
            postgresql_include=[],
            postgresql_nulls_not_distinct=False,
        ),
    )
    op.create_index(
        op.f("idx_project_monthly_forecast_project_key"),
        "project_monthly_forecast",
        ["project_key"],
        unique=False,
    )
    op.create_index(
        op.f("idx_project_monthly_forecast_month_year"),
        "project_monthly_forecast",
        ["month_year"],
        unique=False,
    )
    op.create_table(
        "slack_sessions",
        sa.Column(
            "session_id", sa.VARCHAR(length=32), autoincrement=False, nullable=False
        ),
        sa.Column("data", postgresql.BYTEA(), autoincrement=False, nullable=False),
        sa.Column(
            "created_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "expires_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=False
        ),
        sa.PrimaryKeyConstraint("session_id", name=op.f("slack_sessions_pkey")),
    )
    op.create_table(
        "query_expansions",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column(
            "original_term", sa.VARCHAR(length=100), autoincrement=False, nullable=False
        ),
        sa.Column(
            "expanded_term", sa.VARCHAR(length=100), autoincrement=False, nullable=False
        ),
        sa.Column(
            "expansion_type", sa.VARCHAR(length=20), autoincrement=False, nullable=False
        ),
        sa.Column(
            "confidence_score",
            sa.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column("usage_count", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("success_count", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column(
            "project_key", sa.VARCHAR(length=10), autoincrement=False, nullable=True
        ),
        sa.Column("domain", sa.VARCHAR(length=50), autoincrement=False, nullable=True),
        sa.Column("is_active", sa.BOOLEAN(), autoincrement=False, nullable=False),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("query_expansions_pkey")),
    )
    op.create_index(
        op.f("ix_query_expansions_original_term"),
        "query_expansions",
        ["original_term"],
        unique=False,
    )
    op.create_table(
        "vector_sync_status",
        sa.Column("source", sa.TEXT(), autoincrement=False, nullable=False),
        sa.Column("last_sync", sa.TEXT(), autoincrement=False, nullable=False),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            autoincrement=False,
            nullable=True,
        ),
        sa.PrimaryKeyConstraint("source", name=op.f("vector_sync_status_pkey")),
    )
    op.create_index(
        op.f("idx_vector_sync_source"), "vector_sync_status", ["source"], unique=False
    )
    op.create_table(
        "user_preferences",
        sa.Column("id", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("email", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("slack_username", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "notification_cadence", sa.VARCHAR(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "selected_projects",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "created_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "updated_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "last_notification_sent",
            postgresql.TIMESTAMP(),
            autoincrement=False,
            nullable=True,
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("user_preferences_pkey")),
        sa.UniqueConstraint(
            "email",
            name=op.f("user_preferences_email_key"),
            postgresql_include=[],
            postgresql_nulls_not_distinct=False,
        ),
    )
    op.create_table(
        "celery_tasksetmeta",
        sa.Column("id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column(
            "taskset_id", sa.VARCHAR(length=155), autoincrement=False, nullable=True
        ),
        sa.Column("result", postgresql.BYTEA(), autoincrement=False, nullable=True),
        sa.Column(
            "date_done", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("celery_tasksetmeta_pkey")),
        sa.UniqueConstraint(
            "taskset_id",
            name=op.f("celery_tasksetmeta_taskset_id_key"),
            postgresql_include=[],
            postgresql_nulls_not_distinct=False,
        ),
    )
    op.create_table(
        "meeting_project_connections",
        sa.Column("id", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("meeting_id", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("meeting_title", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "meeting_date", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.Column("project_key", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("project_name", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("relevance_score", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("confidence", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "matching_factors",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "created_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "last_confirmed_at",
            postgresql.TIMESTAMP(),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("is_verified", sa.BOOLEAN(), autoincrement=False, nullable=True),
        sa.PrimaryKeyConstraint("id", name=op.f("meeting_project_connections_pkey")),
    )
    op.drop_index(
        op.f("ix_project_characteristics_project_key"),
        table_name="project_characteristics",
    )
    op.drop_table("project_characteristics")
    op.drop_index(
        op.f("ix_standard_epic_templates_name"), table_name="standard_epic_templates"
    )
    op.drop_table("standard_epic_templates")
    # ### end Alembic commands ###
