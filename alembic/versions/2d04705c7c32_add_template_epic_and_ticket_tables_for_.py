"""Add template epic and ticket tables for Jira imports

Revision ID: 2d04705c7c32
Revises: 500fde9646c5
Create Date: 2025-11-16 09:39:23.291406

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "2d04705c7c32"
down_revision: Union[str, Sequence[str], None] = "500fde9646c5"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "template_epics",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("epic_name", sa.String(length=255), nullable=False),
        sa.Column("summary", sa.String(length=500), nullable=True),
        sa.Column("description", sa.Text(), nullable=True),
        sa.Column("epic_color", sa.String(length=20), nullable=True),
        sa.Column("epic_category", sa.String(length=100), nullable=True),
        sa.Column("sort_order", sa.Integer(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "template_tickets",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("template_epic_id", sa.Integer(), nullable=True),
        sa.Column("issue_type", sa.String(length=50), nullable=False),
        sa.Column("summary", sa.String(length=500), nullable=False),
        sa.Column("description", sa.Text(), nullable=True),
        sa.Column("sort_order", sa.Integer(), nullable=True),
        sa.ForeignKeyConstraint(
            ["template_epic_id"],
            ["template_epics.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.drop_table("vector-sync-status")
    op.drop_table("project_changes")
    op.drop_index(
        op.f("ix_query_expansions_original_term"), table_name="query_expansions"
    )
    op.drop_table("query_expansions")
    op.drop_table("celery_taskmeta")
    op.drop_table("search_feedback")
    op.drop_table("celery_tasksetmeta")
    op.drop_table("meeting_project_connections")
    op.drop_table("slack_sessions")
    op.drop_table("user_preferences")
    op.create_unique_constraint(None, "epic_allocation_baselines", ["epic_category"])
    op.alter_column(
        "epic_budgets",
        "imported_at",
        existing_type=postgresql.TIMESTAMP(),
        type_=sa.DateTime(timezone=True),
        existing_nullable=True,
    )
    op.drop_index(op.f("ix_epic_hours_category"), table_name="epic_hours")
    op.alter_column(
        "job_executions",
        "result_data",
        existing_type=postgresql.JSONB(astext_type=sa.Text()),
        type_=sa.JSON(),
        existing_comment="Task return value as JSON (e.g., {items_processed: 150, channels: 5})",
        existing_nullable=True,
    )
    op.drop_index(op.f("idx_job_executions_recent"), table_name="job_executions")
    op.create_index(
        "idx_job_executions_recent",
        "job_executions",
        ["started_at"],
        unique=False,
        postgresql_using="btree",
        postgresql_ops={"started_at": "DESC"},
    )
    op.drop_index(
        op.f("idx_project_monthly_forecast_month_year"),
        table_name="project_monthly_forecast",
    )
    op.drop_index(
        op.f("idx_project_monthly_forecast_project_key"),
        table_name="project_monthly_forecast",
    )
    op.drop_constraint(
        op.f("project_monthly_forecast_project_key_month_year_key"),
        "project_monthly_forecast",
        type_="unique",
    )
    op.create_index(
        op.f("ix_project_monthly_forecast_month_year"),
        "project_monthly_forecast",
        ["month_year"],
        unique=False,
    )
    op.create_index(
        op.f("ix_project_monthly_forecast_project_key"),
        "project_monthly_forecast",
        ["project_key"],
        unique=False,
    )
    op.create_unique_constraint(
        "unique_project_month",
        "project_monthly_forecast",
        ["project_key", "month_year"],
    )
    op.alter_column(
        "project_resource_mappings",
        "project_key",
        existing_type=sa.TEXT(),
        type_=sa.String(length=50),
        existing_nullable=False,
    )
    op.drop_index(
        op.f("idx_project_resource_mappings_key"),
        table_name="project_resource_mappings",
    )
    op.drop_constraint(
        op.f("project_resource_mappings_project_key_key"),
        "project_resource_mappings",
        type_="unique",
    )
    op.create_index(
        op.f("ix_project_resource_mappings_project_key"),
        "project_resource_mappings",
        ["project_key"],
        unique=True,
    )
    # CRITICAL: DO NOT DROP THESE COLUMNS - Protected after 2025-11-16 data loss incident
    # op.drop_column('projects', 'project_work_type')
    # op.drop_column('projects', 'weekly_meeting_day')
    # op.drop_column('projects', 'description')
    # op.drop_column('projects', 'retainer_hours')
    # op.drop_column('projects', 'launch_date')
    # op.drop_column('projects', 'total_hours')
    # op.drop_column('projects', 'start_date')
    # op.drop_column('projects', 'cumulative_hours')
    # op.drop_column('projects', 'send_meeting_emails')
    op.drop_column("todo_items", "source")
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column(
        "todo_items",
        sa.Column("source", sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    )
    op.add_column(
        "projects",
        sa.Column(
            "send_meeting_emails",
            sa.BOOLEAN(),
            server_default=sa.text("false"),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "projects",
        sa.Column(
            "cumulative_hours",
            sa.NUMERIC(precision=10, scale=2),
            server_default=sa.text("0"),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "projects",
        sa.Column("start_date", sa.DATE(), autoincrement=False, nullable=True),
    )
    op.add_column(
        "projects",
        sa.Column(
            "total_hours",
            sa.NUMERIC(precision=10, scale=2),
            server_default=sa.text("0"),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "projects",
        sa.Column("launch_date", sa.DATE(), autoincrement=False, nullable=True),
    )
    op.add_column(
        "projects",
        sa.Column(
            "retainer_hours",
            sa.NUMERIC(precision=10, scale=2),
            server_default=sa.text("0"),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.add_column(
        "projects",
        sa.Column("description", sa.TEXT(), autoincrement=False, nullable=True),
    )
    op.add_column(
        "projects",
        sa.Column("weekly_meeting_day", sa.TEXT(), autoincrement=False, nullable=True),
    )
    op.add_column(
        "projects",
        sa.Column(
            "project_work_type",
            sa.VARCHAR(length=50),
            server_default=sa.text("'project-based'::character varying"),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.drop_index(
        op.f("ix_project_resource_mappings_project_key"),
        table_name="project_resource_mappings",
    )
    op.create_unique_constraint(
        op.f("project_resource_mappings_project_key_key"),
        "project_resource_mappings",
        ["project_key"],
        postgresql_nulls_not_distinct=False,
    )
    op.create_index(
        op.f("idx_project_resource_mappings_key"),
        "project_resource_mappings",
        ["project_key"],
        unique=False,
    )
    op.alter_column(
        "project_resource_mappings",
        "project_key",
        existing_type=sa.String(length=50),
        type_=sa.TEXT(),
        existing_nullable=False,
    )
    op.drop_constraint(
        "unique_project_month", "project_monthly_forecast", type_="unique"
    )
    op.drop_index(
        op.f("ix_project_monthly_forecast_project_key"),
        table_name="project_monthly_forecast",
    )
    op.drop_index(
        op.f("ix_project_monthly_forecast_month_year"),
        table_name="project_monthly_forecast",
    )
    op.create_unique_constraint(
        op.f("project_monthly_forecast_project_key_month_year_key"),
        "project_monthly_forecast",
        ["project_key", "month_year"],
        postgresql_nulls_not_distinct=False,
    )
    op.create_index(
        op.f("idx_project_monthly_forecast_project_key"),
        "project_monthly_forecast",
        ["project_key"],
        unique=False,
    )
    op.create_index(
        op.f("idx_project_monthly_forecast_month_year"),
        "project_monthly_forecast",
        ["month_year"],
        unique=False,
    )
    op.drop_index(
        "idx_job_executions_recent",
        table_name="job_executions",
        postgresql_using="btree",
        postgresql_ops={"started_at": "DESC"},
    )
    op.create_index(
        op.f("idx_job_executions_recent"),
        "job_executions",
        [sa.literal_column("started_at DESC")],
        unique=False,
    )
    op.alter_column(
        "job_executions",
        "result_data",
        existing_type=sa.JSON(),
        type_=postgresql.JSONB(astext_type=sa.Text()),
        existing_comment="Task return value as JSON (e.g., {items_processed: 150, channels: 5})",
        existing_nullable=True,
    )
    op.create_index(
        op.f("ix_epic_hours_category"), "epic_hours", ["epic_category"], unique=False
    )
    op.alter_column(
        "epic_budgets",
        "imported_at",
        existing_type=sa.DateTime(timezone=True),
        type_=postgresql.TIMESTAMP(),
        existing_nullable=True,
    )
    op.drop_constraint(None, "epic_allocation_baselines", type_="unique")
    op.create_table(
        "user_preferences",
        sa.Column("id", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("email", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("slack_username", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "notification_cadence", sa.VARCHAR(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "selected_projects",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "created_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "updated_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "last_notification_sent",
            postgresql.TIMESTAMP(),
            autoincrement=False,
            nullable=True,
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("user_preferences_pkey")),
        sa.UniqueConstraint(
            "email",
            name=op.f("user_preferences_email_key"),
            postgresql_include=[],
            postgresql_nulls_not_distinct=False,
        ),
    )
    op.create_table(
        "slack_sessions",
        sa.Column(
            "session_id", sa.VARCHAR(length=32), autoincrement=False, nullable=False
        ),
        sa.Column("data", postgresql.BYTEA(), autoincrement=False, nullable=False),
        sa.Column(
            "created_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "expires_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=False
        ),
        sa.PrimaryKeyConstraint("session_id", name=op.f("slack_sessions_pkey")),
    )
    op.create_table(
        "meeting_project_connections",
        sa.Column("id", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("meeting_id", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("meeting_title", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "meeting_date", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.Column("project_key", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("project_name", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("relevance_score", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("confidence", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "matching_factors",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "created_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "last_confirmed_at",
            postgresql.TIMESTAMP(),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("is_verified", sa.BOOLEAN(), autoincrement=False, nullable=True),
        sa.PrimaryKeyConstraint("id", name=op.f("meeting_project_connections_pkey")),
    )
    op.create_table(
        "celery_tasksetmeta",
        sa.Column("id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column(
            "taskset_id", sa.VARCHAR(length=155), autoincrement=False, nullable=True
        ),
        sa.Column("result", postgresql.BYTEA(), autoincrement=False, nullable=True),
        sa.Column(
            "date_done", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("celery_tasksetmeta_pkey")),
        sa.UniqueConstraint(
            "taskset_id",
            name=op.f("celery_tasksetmeta_taskset_id_key"),
            postgresql_include=[],
            postgresql_nulls_not_distinct=False,
        ),
    )
    op.create_table(
        "search_feedback",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column("user_id", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "slack_user_id", sa.VARCHAR(length=50), autoincrement=False, nullable=True
        ),
        sa.Column("query", sa.TEXT(), autoincrement=False, nullable=False),
        sa.Column("rating", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("feedback_text", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column("result_count", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "result_sources",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "top_result_source",
            sa.VARCHAR(length=50),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "detail_level", sa.VARCHAR(length=20), autoincrement=False, nullable=True
        ),
        sa.Column(
            "project_key", sa.VARCHAR(length=10), autoincrement=False, nullable=True
        ),
        sa.Column("response_time_ms", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column("summary_length", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("search_feedback_pkey")),
    )
    op.create_table(
        "celery_taskmeta",
        sa.Column("id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column(
            "task_id", sa.VARCHAR(length=155), autoincrement=False, nullable=True
        ),
        sa.Column("status", sa.VARCHAR(length=50), autoincrement=False, nullable=True),
        sa.Column("result", postgresql.BYTEA(), autoincrement=False, nullable=True),
        sa.Column(
            "date_done", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.Column("traceback", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column("name", sa.VARCHAR(length=155), autoincrement=False, nullable=True),
        sa.Column("args", postgresql.BYTEA(), autoincrement=False, nullable=True),
        sa.Column("kwargs", postgresql.BYTEA(), autoincrement=False, nullable=True),
        sa.Column("worker", sa.VARCHAR(length=155), autoincrement=False, nullable=True),
        sa.Column("retries", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column("queue", sa.VARCHAR(length=155), autoincrement=False, nullable=True),
        sa.PrimaryKeyConstraint("id", name=op.f("celery_taskmeta_pkey")),
        sa.UniqueConstraint(
            "task_id",
            name=op.f("celery_taskmeta_task_id_key"),
            postgresql_include=[],
            postgresql_nulls_not_distinct=False,
        ),
    )
    op.create_table(
        "query_expansions",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column(
            "original_term", sa.VARCHAR(length=100), autoincrement=False, nullable=False
        ),
        sa.Column(
            "expanded_term", sa.VARCHAR(length=100), autoincrement=False, nullable=False
        ),
        sa.Column(
            "expansion_type", sa.VARCHAR(length=20), autoincrement=False, nullable=False
        ),
        sa.Column(
            "confidence_score",
            sa.DOUBLE_PRECISION(precision=53),
            server_default=sa.text("'1'::double precision"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "usage_count",
            sa.INTEGER(),
            server_default=sa.text("0"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "success_count",
            sa.INTEGER(),
            server_default=sa.text("0"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "project_key", sa.VARCHAR(length=10), autoincrement=False, nullable=True
        ),
        sa.Column("domain", sa.VARCHAR(length=50), autoincrement=False, nullable=True),
        sa.Column(
            "is_active",
            sa.BOOLEAN(),
            server_default=sa.text("true"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("query_expansions_pkey")),
    )
    op.create_index(
        op.f("ix_query_expansions_original_term"),
        "query_expansions",
        ["original_term"],
        unique=False,
    )
    op.create_table(
        "project_changes",
        sa.Column("id", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("project_key", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("change_type", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("ticket_key", sa.VARCHAR(), autoincrement=False, nullable=False),
        sa.Column("ticket_title", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("old_value", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("new_value", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("assignee", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("reporter", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("priority", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("status", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "change_timestamp",
            postgresql.TIMESTAMP(),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "detected_at", postgresql.TIMESTAMP(), autoincrement=False, nullable=True
        ),
        sa.Column(
            "change_details",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("project_changes_pkey")),
    )
    op.create_table(
        "vector-sync-status",
        sa.Column("source", sa.TEXT(), autoincrement=False, nullable=False),
        sa.Column("last_sync", sa.TEXT(), autoincrement=False, nullable=False),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            autoincrement=False,
            nullable=True,
        ),
        sa.PrimaryKeyConstraint("source", name=op.f("vector-sync-status_pkey")),
    )
    op.drop_table("template_tickets")
    op.drop_table("template_epics")
    # ### end Alembic commands ###
